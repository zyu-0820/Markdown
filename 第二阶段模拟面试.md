xxxxxxxxxx 云计算工程师做"选择题"​https://gitee.com/markhahaha/NSDTN2024​=================================================================​第二阶段​    CLUSTER:4天        集群:2天,LVS/KEEPALIVED/HAPROXY        存储:2天,Ceph    SECURITY:5天        监控:3天,Zabbix/Prometheus        安全:2天,Kali/nmap/tcpdump/wireshark/iptables    PROJECT01:2天,高可用负载均衡web集群,WordPress---------------------------------------------------集群:    集群分类:        按功能分类:            高性能集群            高可用集群:故障自动切换(备胎)            负载均衡集群:压力分摊        按架构分类:            中心化架构集群            非中心化架构集群​    负载均衡软件:        LVS:Linux virtual Server            组成:                内核空间:IPVS框架                用户空间:ipvsadm命令            工作模式:                NAT:地址转换模式   net.ipv4.ip_forward                DR:直连路由模式                TUN:隧道模式        NGINX:能够做web服务器,也能做反向代理服务器​        HAPROXY:天生的负载均衡器​    负载均衡软件选择:        LVS:负载特别大的站点        NGINX:负载比较小的站点        HAPROXY:负载较大且需要七层回话处理​        功能:LVS<HAPROXY<NGINX        性能:LVS>HAPROXY>NGINX​​​​    代理和调度:        代理:            负载均衡软件工作于OSI七层            需要对客户端的包进行深层次解析后发往真实服务器        调度:            负载均衡软件工作于OSI四层            无法识别典型的应用层协议,仅做流量调度分发----------------------------------------------------存储    解决方案:        硬件层面:存储柜        软件层面:分布式存储系统(SDS:soft define storage)​Ceph:分布式存储解决方案        组件化设计思想​    版本:v17  Qunicy   ​    存储提供形式:        块存储        文件存储        对象存储​    组件:        MON:monitor,整个集群的监控,绘制OSD地图        MGR:manager,管理组件,提供了一个对于ceph的web管理界面        OSD:objective stroage deamon,负责集群内部的数据存储        MDS:meatadata service,元数据服务器        RGW:rados gateway,网关服务​        搭建准备工作:        1、更新自定义yum源ceph相关软件        2、配置hosts文件解析主机名            192.168.88.240 quay.io        3、配置各节点yum源        4、配置时间服务        5、各个节点安装必要软件:podman/python39/lvm2        6、搭建私有镜像仓库            6.1、搭建私有仓库  5000-->80            6.2、导入ceph相关镜像                podman load -i xx.tar            6.3、推送ceph镜像到私有仓库                podman push quay.io/ceph/ceph:v17        7、配置各个节点识别私有镜像仓库        8、Ceph节点关机打快照​​    搭建流程:        1、初始化集群(cephadm)            # ./cephadm bootstrap \            > --mon-ip 192.168.88.11 \            > --initial-dashboard-password=123456 \            > --dashboard-password-noupdate \            > --skip-monitoring-stack            # podman images | wc -l   ==> 2            # podman ps | wc -l       ==> 4        2、同步ceph的ssh公钥            # ssh-copy-id -f -i /etc/ceph/ceph.pub root@ceph1        3、集群扩容            # ceph orch host add ceph2 192.168.88.12        4、绑定OSD组件            a) # ceph orch daemon add osd ceph1:/dev/vdb            b) # ceph orch apply osd --all-available-devices        5、检查集群状态            # ceph -s             # ceph orch ls​    ​    补充:清理集群方法        # ceph mgr module disale cephadm        # ceph fsid        # cephadm rm-cluster --force --zap-osds --fsid <fsid>​    存储池:pool,Ceph中存储资源类型的逻辑区分        类似于Windows中的文件夹,仅做存储数据类型的区分​    块存储:Rados Block Device        优点:读写速度快,多节点IO        缺点:不能用于多节点共享​        场景:应用服务器需要进行大量读写操作,典型代表是数据库服务器​        COW技术:Copy ON Write,写时复制​​    文件存储:Ceph FS        优点:允许多客户端同时挂载        缺点:读写速度比块要慢​        场景:多机共享文件​    对象存储:Ceph Rados Gateway,   web服务        优点:适用于非结构化数据        缺点:开发难度大​        场景:网站资源解耦(网页资源与静态资源分离)​        数据分类:            结构化数据:可以存储到关系型数据库中的数据,典型代表字符串            非结构化数据:不适合存储到数据库中的数据,典型代表图片-----------------------------------------------------------监控:    Zabbix:开源分布式监控解决方案,适用于传统服务器硬件指标监控​        架构:            数据采集存储部分            数据展示部署(web)​        组成部分:            MySQL:监控数据的持久化存储            zabbix-server(C):接收监控数据并存储到数据库            zabbix-agent(C):负责采集数据            zabbix-web(php):用于数据展示​        zabbix中的概念:            主机:被监控端,zabbix体系中的被监控单位            主机群组:主机分组管理​            监控项:数据采集最小单位                自定义监控:                    UserParamter=key[*],command $1            模板:监控项分组单位​            用户:登录zabbix的用户            用户群组:多用户管理​            触发器:定义阈值表达式            触发器动作:阈值触发后的行为​            报警媒介:报警的方式方法,如邮件/短信/第三方机器人等​                zabbix自动发现:自动发现被监控端的机制            自动发现规则:定义扫描规则并按照指定时间间隔持续扫描            自动发现动作:发现新节点后的行为​​        zabbix工作模式:(对象为被监控端)            被动模式:                server向agent发起索要监控数据的请求                agent接收请求后发送监控数据                server接收到监控数据后存储到数据库            主动模式:                agent主动向server推送监控数据                server接收到监控数据后存储到数据库​    Prometheus:开源的新兴监控解决方案,更加适用于容器领域​        组件:            Prometheus-Server:监控数据收集和存储            xx-exporter:数据采集单位            pushgateway:push模式必要组件            alertmanager:告警组件                去重/分组/路由/静默/抑制            grafana:数据看板​        工作模式:默认为pull模式            pull模式:Server向exporter发起数据索要请求            push模式:exporter主动推送数据到server,需要gateway​        自动发现:自动监控exporter            基于文件自动发现            基于k8s自动发现            ...======================================================安全:    Kali:适用于网络安全领域的操作系统        "Kali用得好,班房蹲的早,牢饭吃得饱"    扫描:nmap        -sP/-sS/-sT/-sU/-A        --script    加密:        对称加密        非对称加密        john:枚举式破解密码工具    抓包:        tcpdump            -i eth0 -A -w xx.cap host xx and tcp port xx        wireshark:图形化抓包工具​    NGINX服务加固        隐藏版本号: server_tokens off;        Ddos攻击防护            dos攻击:                (deny of service)                拒绝服务攻击            ddos攻击:                (distribute deny of service)                分布式拒绝服务攻击        防内存溢出            Linux系统加固        用户安全            用户有效期:chage            用户锁定:passwd -S/-l/-u 用户名        文件安全            i属性:只允许查看,不允许修改            a属性:只允许追加和查看,不允许其它操作​    iptables防火墙​        iptables和firewalld​        组成:            内核空间:net-filter框架            用户空间:iptables命令​​        四表            raw:状态跟踪表            mangle:包标记表            filter:包过滤表            nat:地址转换表        五链            INPUT:入站链            OUTPUT:出站链            FORWARD:转发链            PREROUTING:路由前链            POSTROUTING:路由后链​        作用类型:            主机型防火墙:保护自己            网络型防火墙:保护其它主机​        语法:            iptables [-t 表名] 选项 [链名] [条件] [-j 操作]                -P/-A/-I/-F/-D/-nL                -s/-d/-p/--sport/--dport                -m state|multiport/iprange​        规则配置方式:            白名单:默认拒绝,添加明确允许的规则            黑名单:默认允许,添加明确拒绝的规则​        地址转换用法:iptables -t nat -A POSTROUTING -s 192.168.88.0/24 -j SNAT --to-source 192.168.99.11iptables -t nat -A POSTROUTING -s 192.168.88.0/24 -j MASQUERADEiptables -t nat -A PREROUTING -d 192.168.88.11 -p tcp --dport 8080 -j DNAT --to-destination 192.168.99.100:80​==============================================================项目实战:(高可用负载均衡web集群)        开发体系:        项目研发的设计逻辑:            前后端不分离设计:前后端代码放在一起            前后端分离设计:前后端代码分开存放​        什么是前后端:            前端:与用户交互的部分,资源的展示方法                HTML/CSS/JS            后端:项目业务逻辑支撑                Java/php/Python/Go/C++​    PHP类网站架构:        LAMP:Linux/Apache/MySQL/php-fpm        LNMP:Linux/NGINX/MySQL/php-fpm​    架构优化逻辑:        横向优化:添加同类型的服务器        纵向优化:做组件的拆分处理==============================================================第三阶段课程介绍:数据库:10天    MySQL:8天        MySQL使用            SQL语句:5天                库表管理                表记录增删改查                索引/权限        MySQL数据备份与还原:1天        MySQL架构:2天            MySQL主从同步            MySQL读写分离            MySQL分库分表    Redis:2天        Redis使用            Redis指令            数据类型        Redis数据持久化        Redis架构            Redis主从同步            Redis哨兵服务            Redis分布式高可用集群项目二:4天    CICD技术路线    HIS项目========================================================MySQL数据库:    数据是什么?        用户信息/订单信息/行程信息...    数据库又是什么 ?        在服务端实现数据存储的一类软件的统称​    数据库分类:        关系型数据库            1/数据持久化存储            2/数据结构化存储            3/数据之间可以建立关联        非关系型数据库            1/数据灵活存储            2/数据处理速度快---------------------------------------------------------​MySQL基础:    MySQL服务器构建:        rpm:课堂案例,rockylinux8.6 --> MySQL-8.0.26        源码        容器    MySQL登录:        -h:数据库服务器地址        -P:数据库服务端口        -u:登录用户        -p:登录密码        -S:指定socket文件        -e:非交互式执行SQL语句        MySQL用户密码管理        Linux命令行: # mysqladmin 命令        MySQL命令行: > alter user 语句​        root用户破解: skip_grant_tables,用于跳过密码认证​    MySQL图形工具:        PHPMyAdmin        MySQL-WorkBench        DBeaver​    数据库操作分类:        读操作:不引起数据变化​        写操作:引起数据变化​​    查询语句:        select 字段列表 from 库名.表名        [连接方式] join 库名.表名        on        连接条件        ...        where     分组前筛选        group by  分组字段        having    分组后筛选        order by  排序字段        limit n   分页显示​​​        连表查询:            连接方式:                交叉连接:笛卡尔积                内连接:inner                外连接:                    左外连接:left                    右外连接:right                    全外连接:full-->union            连接条件:                等值连接                不等值连接        嵌套查询:(贪吃蛇)            where后:     筛选条件是表中真实数据            having后:    筛选条件是过程参数            from后:      select子句作为临时表            select后:    select子句作为字段,外层SQL执行时逐行传参​​        筛选条件:            字符串比较:=/!=            数值比较:=/!=/>/>=/</<=            范围匹配:in/not in/between x and y            模糊匹配:like   _  %            正则匹配:regexp 正则元字符            逻辑比较:and/or/not/()/&&/||/!            空与非空:is null/is not null​        查询结果处理:            别名:as            去重:distinct            合并:concat()/concat_ws()​​        MySQL内置函数:            字符函数:                length()/char_length()                upper()/lower()                substr()/instr()/trim()            数学函数:                abs()/pi()/mod()/ceil()/floor()/round()            日期时间函数:                now()/curdate()/curtime()                year()/month()/day()                hour()/minute()/second()                date()/time()                monthname()/dayname()                week()/weekday()/quarter()                dayofyear()/dayofmonth()            加密函数:md5()            聚集函数:                sum()/max()/min()/avg()/count()            流程控制函数:                if()/ifnull()/case​​​    增删改语句        增:            insert into 库名.表名(字段列表) values             (v1,v2...),(v1,v2...)            insert into 库名.表名(字段列表) (select语句)            insert into 库名.表名 set c1=v1,c2=v2...        改:            update 库名.表名 set c1=v1,c2=v2 where 条件        删:            delete from 库名.表名 where 条件​​        select语句执行顺序        FROM子句：确定数据来源，包括JOIN的表        ON：执行JOIN条件        JOIN：如果有JOIN，根据JOIN类型（如INNER、LEFT），将两个表进行合并        WHERE子句：过滤记录        GROUP BY子句：根据指定的列分组记录        聚合函数:对除分组之外的字段进行处理        HAVING子句：过滤分组        SELECT子句：选取特定的列        DISTINCT子句：去除重复数据        ORDER BY子句：最后对结果进行排序        LIMIT子句：最后的结果截取     ​​    库管理语句:        show databases;        create database if not exists xx;        use xx;        select database();        show create database xx;        drop database if exists xx;​    表管理语句:        show tables from xx;        create table xx (x x,x x,...);        desc xx;        show create table xx;        drop table xx;​        alter table xx (add/modify/change/drop/rename);​    MySQL数据类型:        字符类型:char/varchar/text/blob        数值类型:            整型:tinyint/smallint/mediumint/int/bigint            浮点型:float/double            符号:unsigned        枚举类型:enum/set        日期时间类型:year/date/time/datetime/timestamp​    数据批量处理:        数据导入:            load data infile "文件名" into table 表名            lines terminated by "换行符"            fields terminated by "分隔符";        数据导出:            select 字段列表 from 表名 ...            into outfile "文件名"            lines terminated by "换行符"            fields terminated by "分隔符";​    表字段约束:        基本约束:            空与非空:是否可以赋空值 not null            默认值:赋值时不指定字段填充内容 default        高级约束:            唯一约束:字段值唯一但可以为空 unique            主键约束:字段值唯一且不能为空 primary key            自增约束:不指定值默认对已有最大值做自增处理 auto_increment            外键约束:表之间数据建立关联(动态枚举) foreign key​            结论:                1/一张表中能有1个主键                2/主键字段不一定自增,但被标记自增的字段一定是主键​​    SQL语句分类：        DDL:database define language，数据定义语句            create/alter/drop        DML:database manager language，数据操作语句            insert/update/delete        DQL:database query language，数据查询语句            select/show        DCL:database control language，数据控制语句            grant/revoke        TCL:transcation control language，事务控制语句            begin/commit/savepoint/rollback  ​    事务：          针对于DML        一组SQL语句要么全部执行，要么全部不执行        是保证数据准确性的机制                    特性：            原子性(Auomicity):在一个事务中，像增删改（DML）要么全部成功，要么全部失败            一致性(Consistency)：事务完成时必须所有数据都保持一致状态            隔离性(Isolation)：多个事务的执行是互不干扰的            持久性(Durability)：事务一旦提交或回滚，它对数据库中的数据的改变就是永久的​    索引:数据结构,加速查询        分类:            作用效果:                普通索引:字段值无约束         mul                唯一索引:字段值唯一但可以赋空值    uni                主键索引:字段值唯一且不能赋空值    pri            作用字段:                单列索引:作用于一个字段                多列索引/复合索引:作用于多个字段,从最左字段开始匹配            存储方式:                聚簇索引:数据和索引存放在一起                非聚簇索引:数据和索引不在一起            数据结构:                树形索引:btree/b+tree   正排表:根据行号找内容                哈希索引:hash                全文索引:fulltext                空间索引:    用户权限管理体系        用户管理:            create user name@addr identified by '密码';            alter user name@addr identified by '密码';            rename user name@addr to name@addr;            drop user name@addr;            select user,host from mysql.user;        权限管理:            grant 权限列表 on 库.表 to name@'addr';            revoke 权限列表 on 库.表 from name@'addr';            show grants for name@'addr';            flush privileges;        权限二阶段验证:            第一阶段:所提供的用户是否可以登录MySQL服务            第二阶段:所发出的SQL请求是否有足够的权限执行        权限分布:            用户信息                --> mysql.user            全局权限 *.*            --> mysql.user            库权限   db.*          --> mysql.db            表权限   db.tb         --> mysql.tables_priv            字段权限 db.tb(col) --> mysql.tables_priv/mysql.columns_priv​=========================================================================​​MySQL数据备份与恢复    数据备份三要素:BW/RPO/RTO        备份方式:数据库服务器的运行状态        冷备份:在数据库服务停止运行的状态下做数据备份            cp/tar/zip        温备份:数据库服务运行状态下进行数据备份,数据库的读操作可以正常自行但写操作会被阻塞            mysqldump        热备份:在数据库服务正常运行的状态下做数据备份,数据库读写请求都不受影响            xtrabackup                --host --port --user --password --datadir --backup                --target-dir --incremental-basedir                --prepare --apply-log-only --incremental-dir        备份数据:        物理备份:数据库的磁盘文件        逻辑备份:备份时刻下数据库的库表的SQL语句​    备份策略:        完整备份:        部分备份:            差异备份            增量备份​​    两地三中心        北京:平谷/通州        新疆:乌鲁木齐​    MySQL中的锁:        锁类型:            读锁:共享锁            写锁:排它锁/互斥锁        锁粒度            行级锁            表级锁            页级锁​​    MySQL的日志:        错误日志:MySQL运行信息        查询日志:所有的查询相关语句        慢查询日志:超过指定时间阈值的查询语句        二进制日志:所有引起数据改变的语句        中继日志:主从同步中用到的过渡性日志        事务日志:事务管理相关日志            重做日志:保证事务持久性的日志            回滚日志:保证事务原子性的日志​​​​    实时备份:binlog日志        配置：log_bin        查看日志：            show master status  #当前使用的            show binary logs    #所有的        刷新日志：            1、达到默认大小自然刷新            2、flush logs            3、mysqldump --flush-logs            4、重启MySQL服务        清理日志：            1、purge master logs to xx            2、reset master            3、到达默认存储期限自动删除​​​​            ​    数据备份推荐方案:        1、冷备份                    开发、测试环境                           2、mysqldump+lvm-snapshot   内部系统，数据量小        3、mysqldump+binlog         内部系统，数据量中        4、xtrabackup               外部业务，数据量大​==================================================================MySQL架构设计:    MySQL主从同步:用于解决多个MySQL服务器之间数据实时同步的解决方案        工作原理:通过复现主服务器binlog日志中所记录的SQL语句来实现数据实时同步​        结构模式:宏观维度,研究多个MySQL服务器之间的关系            一主一从:搭建简单,副本少            一主多从:副本多且无关联,主节点负载高            链式复制:主节点负载相对低,但副本之间存在关联            互为主从:多节点写入容易造成死锁                复制模式:微观模式,研究MySQL主从同步中的性能问题            异步复制:主服务器完成SQL后直接返回结果            半同步复制:主服务器完成SQL后等待任意一个从完成IO线程动作后返回            全同步复制:主服务器完成SQL后等待所有从完成数据同步后返回结果​        主从同步搭建流程:            主服务器：                      1、安装MySQL并启动服务                2、配置binlog日志和server_id                3、授权主从同步用户                4、备份已有数据            从服务器：                1、安装MySQL并启动服务                2、还原主服务器备份数据                3、配置server_id(从服务器不严格要求启用binlog日志)                4、change master to语句      设置主服务器信息                    master_host=主服务器地址,                    master_port=主服务器端口,                    master_user=登录主服务器用户,                    master_passowrd=登录主服务器密码,                    master_log_file=主服务器正在使用的binlog日志,                    master_log_pos=主服务器当前binlog日志偏移量;                5、启动io/sql线程，start slave;            错误处理：                > stop slave;               #停止io/sql线程                > reset slave;              #重置主从信息                > change master to 语句     #重新配置主从同步                > start slave;              #启动io/sql线程 ​    MySQL读写分离:MySQL主从同步的增强架构,用于解决主服务器负载过高的方案        主服务器工作内容:            1/对外的写请求的处理            2/对外的读请求的处理            3/发送binlog日志内容到各个从服务器        实现方式:            1/客户端分离:开发者在代码中进行手工分离            2/服务端分离:加设MySQL主从同步组代理服务器                工作内容:                    1/识别各个数据节点的工作状态                    2/识别各个数据节点的角色                    3/承接客户端的数据库连接请求                    4/按照"主写从读"的规则进行请求的分发                    5/收集数据节点的SQL执行结果返还给客户端        解决方案:            mysql-proxy/mysql-router/maxscale            amoeba/cobar/mycat/mycat2            atlas/kingshard/vitess​        mycat2:基于Java语言研发的MySQL读写分离中间件            配置维度:                用户:登录MyCat的用户,区别于MySQL用户                数据源:数据节点相关信息                集群:数据节点间关联关系声明                逻辑库:库表关联关系            配置方法:                冷配置:手搓配置文件,重启服务后生效                热配置:在mycat的SQL命令行下以注释的方法进行配置,无需重启服务,即时生效​​###############mycat2热配置模板####################/*+ mycat: showusers{} */; /*+ mycat: createuser{"name":"xx","password":"xx"...} */; /*+ mycat: dropuser{"name":"xx"} */;        /*+ mycat: showdatasources{} */; /*+ mycat: createdatasource{"name":"xx"...} */; /*+ mycat: dropdatasource{"name":"xx"} */;        /*+ mycat: showclusters{} */; /*! mycat: createcluster{"name":"xx"...} */; /*! mycat: dropcluster{"name":"xx"} */;        /*+ mycat: showschemas{} */; /*+ mycat: createschema{"name":"xx"...} */; /*+ mycat: dropschema{"name":"xx"} */; ​​​​/*+ mycat: createdatasource{"name":"whost56","url":"jdbc:mysql://192.168.88.56:3306/","user":"plja","password":"123456"}*/; ​​/*+ mycat: createdatasource{"name":"rhost57","url":"jdbc:mysql://192.168.88.57:3306/","user":"plja","password":"123456"}*/;​/*+ dropdatasource {"name":"xx"}*/;---------------------------------------/*! mycat: createcluster{"name":"rwcluster","masters":["whost56"],"replicas":["rhost57"]}*/; ​/*! dropcluster {"name":"xx"} */;​        MySQL分库分表:解决单个MySQL服务器存储上限的解决方案:        存储问题:            1/存储层面:分布式存储            2/MySQL层面:分库分表        拆分维度:            分库:把一个库拆分为多个库            分表:把一张表拆分为多个表        拆分方法:            横向切分            纵向切分        常用组合:            垂直分库+水平分表        解决方案:            mycat/mycat2/shardingSphere/vitess​​[root@mysql59 ~]# for i in 192.168.88.{59..63}> do> ssh $i "yum -y install mysql-server;systemctl enable mysqld --now"> done​/*+ mycat:createdatasource {    "name":"dw0",    "url":"jdbc:mysql://192.168.88.59:3306/",    "user":"plj",    "password":"123456"}*/;/*+ mycat:createdatasource {    "name":"dr0",    "url":"jdbc:mysql://192.168.88.60:3306/",    "user":"plj",    "password":"123456"}*/;/*+ mycat:createdatasource {    "name":"dw1",    "url":"jdbc:mysql://192.168.88.61:3306/",    "user":"plj",    "password":"123456"}*/;/*+ mycat:createdatasource {    "name":"dr1",    "url":"jdbc:mysql://192.168.88.62:3306/",    "user":"plj",    "password":"123456"}*/;/*+ mycat:showdatasources{} */;   -->  返回5个数据源      16:05继续​​/*! mycat:createcluster{    "name":"c0",    "masters":["dw0"],    "replicas":["dr0"]}*/;/*! mycat:createcluster{    "name":"c1",    "masters":["dw1"],    "replicas":["dr1"]}*/;/*+ mycat:showclusters{}*/;       -->  返回3个集群​​​​​create database tarena; ​create table tarena.employees(employee_id int primary key,name char(10),dept_id int,mail varchar(30))dbpartition by mod_hash(employee_id)tbpartition by mod_hash(employee_id)dbpartitions 2tbpartitions 1;​insert into tarena.employees values(6,'bob',1,'bob@qq.com'),(7,'tom',2,'tom@qq.com'),(8,'lucy',2,'lucy@qq.com'),(9,'lily',3,'lily@qq.com');​[root@mysql59 ~]# mysql -e "select * from tarena_0.employees_0;"[root@mysql61 ~]# mysql -e "select * from tarena_1.employees_1;"​mycat63.tarena.employees =    mysql59.tarena_0.employees_0 + mysql61.tarena_1.employees_1​​ER表:后创建的表如果与已存在的表使用相同的分库分表字段则自动建立er关系,后创建的表的分片规则如果较已有表更简单则默认遵守已存在表的复杂分库分表规则​create table tarena.salary(employee_id int primary key,p_date date,basic int,bonus int)dbpartition by mod_hash(employee_id)tbpartition by mod_hash(employee_id)tbpartitions 1;​insert into tarena.salary values(6,'20240110',10000,1000),(7,'20240110',10000,2000),(8,'20240110',10000,3000),(9,'20240110',10000,4000);​/*+ mycat: showergroup {} */;​[root@mysql59 ~]# mysql -e "select * from tarena_0.employees_0;"[root@mysql59 ~]# mysql -e "select * from tarena_0.salary_0;"[root@mysql61 ~]# mysql -e "select * from tarena_1.employees_1;"[root@mysql61 ~]# mysql -e "select * from tarena_1.salary_1;"​​全局表:不做分片处理,数据多副本存储(每个数据节点上都有完整的数据)​create table tarena.dept(dept_id int primary key,dept_name char(10)) broadcast;​insert into tarena.dept values(1,"开发部"),(2,"运维部"),(3,"测试部");​[root@mysql59 ~]# mysql -e "select * from tarena.dept;"[root@mysql61 ~]# mysql -e "select * from tarena.dept;"​​​    MySQL高可用解决方案:        MySQL双主+Keepalived        MySQL-MMM集群        MySQL-MHA集群        MySQL-Galera集群        PXC集群        MySQL-MGR集群​=========================================================================非关系型数据库:补充关系型数据库的不足,数据的处理速度    键值对数据库:key:value                    Redis    文档数据库:行数据库,数据以行为单位进行存储      ElasticSearch    列数据库:数据以列为单位进行存储                Hbase    图形图像数据库:专门处理图像/视频的数据库       Neo4j​Redis数据库:    远程字典服务,将数据存放于内存中,追求数据的极致处理速度​    应用场景:缓存服务器/计数器/排行榜/分布式锁/Session共享​    安装方法:        1/rpm安装        2/源码安装        3/容器部署    连接方式:        redis-cli -h Redis服务器地址 -p 端口 -a 认证密码​    常用指令:        ping/set/get/mset/mget/keys/info        type/ttl/expire/exists/move/select        del/flushdb/flushall​    Redis分布式高可用集群:解决单个Redis存储上限的解决方案        高可用:主从同步层面,主节点故障后从节点自动接替主节点角色和哈希槽        分布式:            哈希槽(hash slots):                哈希:算法   crc(key)=数字                槽:逻辑区分  数字%16384    0-16383        结论:判断集群是否正常工作的标准16384个哈希槽是否被完全划分​[root@host51 ~]# for i in 192.168.88.5{1..6}> do> ssh $i "yum -y install redis"> done​​​[root@host51 ~]# for i in 192.168.88.5{2..6}> do> scp /etc/redis.conf root@$i:/etc/> ssh $i "systemctl enable redis --now"> done​​    LNMP+Redis:Redis作为缓存服务器的效果        安装php操作redis扩展的方法        缓存服务器介入后请求的路径变化​​​​    Redis主从同步:多个Redis服务器数据实时同步的解决方案        工作原理:            从服务器向主服务器发送sync命令            主服务器接收到请求后触发bgsave命令,进行rdb数据持久化,同时开辟内存缓冲区            发送rdb文件到从服务器,从服务器对rdb文件进行热加载            发送内存缓冲区中命令到从服务器,从服务器复现写指令        结构模式:            一主一从            一主多从            链式复制        配置方法:            冷配置:修改/etc/redis.conf文件,重启服务            热配置:Redis命令行下执行配置命令,回写配置文件        细节:Redis主从结构中从服务器只读​    Redis哨兵服务:Redis读写分离和高可用解决方案        特性:            作为特殊的Redis节点承接客户端连接但本地不存储数据            监控Redis主从同步复制组            将请求以 主写从读 的规则进行分发,实现读写分离            Redis主从复制组内主节点故障进行故障自动切换        部署架构:            单节点部署            集群部署        工作原理:            定期向Redis复制组内节点发送info命令获取节点状态            主节点故障时所有哨兵节点进行投票确认故障结果并选择工作节点            获取所有从中最接近故障主的节点发送 replicaof no one指令将该节点升级为新主            向其它从发送replicaof newip port更新主服务器配置            持续监控故障主节点,被修复后故障主节点自动加入集群​    Redis数据持久化:        概念:Redis的数据备份的方式,不是把Redis的数据向MySQL一样存储硬盘!!!        实现方式:            RDB:拍照片                Redis database backup                定期将内存中的数据以快照的形式备份到硬盘                特性:速度快/文件体积小,适合大规模的数据备份,可能丢失的数据量比较大                触发契机:                    1/手工执行bgsave命令                    2/Redis服务正常退出                    3/key的变化量触发配置文件的save规则            AOF:写日记                append only file                将Redis执行过的写操作的执行记录到指定文件中                特性:速度慢/文件体积大,适合效果的数据备份,数据丢失量小​        应用:混合持久化,rdb做完整备份,aof做增量备份​    Redis数据类型:        字符类型(string)：            set/get/mset/mget/append/strlen/getrange/            incr/incrby/decr/decrby        列表类型(list)：            lpush/rpush/lpop/rpop/lindex/lset/linsert/llen/lrange        散列类型(hash)：            hset/hget/hmset/hmget/hdel/hlen/hkeys/hvals/hgetall        无序集合(set)：            sadd/srem/smembers/sismember/srandmember            spop/scard/sinter/sdiff/sunion        有序集合(sort set)：            zadd/zrange/zrank/zrevrank/zscore/zincrby/zrem​==========================================================================PROJECT02:4天    HIS项目    CICD技术路线​​    电商:        用户管理模块        商家管理模块        商品管理模块        订单管理模块        库存管理模块        支付管理模块        售后管理模块​        注册中心:Nacos/zk/redis/etcd​版本控制:    基于 "文件的" 版本控制     xx_v1.doc  xx_格式修订_v2.doc xx_论证补充_v3.doc...    基于 "状态的" 版本控制        快照--目录​    分类:        集中式版本控制系统        分布式版本控制系统 Git​    Git核心概念:        工作区:被Git管理的目录下        暂存区:index文件,存放更新文件名单        本地仓库:本地私有版本库        远程仓库:远程公用版本库​    Git中的文件状态:        未跟踪-->已暂存-->已提交-->已修改​    Git指针:head指针可以在任何版本和分支上移动的标记,想看哪里指哪里​​    环境区分:          dev分支              开发环境 --> 开发工程师​    代码                  测试环境 --> 测试工程师​          主分支              生产环境 --> 用户​    ​​​​    Git核心命令:        config/init/add/commit/status/log        reset --heard/reflog        branch/checkout/merge/tag        clone/push/pullbash

1.脚本的执行方式

```bash
source或. 脚本路径 当前SHELL环境
bash/sh等 脚本路径 子shell环境执行
./脚本名 需执行权限且在脚本首行指定解释器

```

2.有哪几种循环方式，格式，退出循环的方式

```bash
for i in 变量列表
do
	命令序列
done
while []
do
done
break
continue
exit
```

3.有哪几种条件判断的方式

```bash
if [];then
elif [];then
else
fi
case 变量 in
 1)  ;;
 2)  ;;
 *)  ;;
 esac
 
```

4.掐头去尾的格式，以及其他做字符串截取的方式，区分 $[] ${}$()的区别shell常见的变量的含义，如:$$ $?$*等等

```bash
${var:start:length}
${var#*关键字}
${var%关键字*}
```

5.常见的变量的含义，如:$$ $? $*等等

```bash
$$ 进程PID
$? 命令执行结果
$* 所有参数
```

6.sed如实现删除，修改，插入等操作的指令和格式

```bash
sed 'nd' file #删除n行
sed '1i xx' user
```

7.grep 常见的几个选项，如过滤空行，不区分大小写

```bash
-v，取反匹配（不包含）
-i，忽略大小写
^word 以字符串word开头
word$ 以字符串word结尾
^$表示空行
-q：静默输出
```

8.几个基本的正则符号的使用

|     ^     | 匹配行首                                 |
| :-------: | ---------------------------------------- |
|    \$     | 匹配行尾                                 |
|    \[]    | 集合，匹配集合中的任意单个字符           |
|   \[^]    | 对集合取反                               |
|     .     | 匹配任意单个字符                         |
|    \*     | 匹配前一个字符任意次数 [*不允许单独使用] |
| \\{n,m\\} | 匹配前一个字符n到m次                     |
|  \\{n\\}  | 匹配前一个字符n次                        |
| \\{n,\\}  | 匹配前一个字符n次及以上                  |
|  \\(\\)   | 组合为整体，保留                         |

9.awk的选项和常见的几个带的变量，另外会默写统计日志文件ip出现次数的那段数组脚本

```bash
-F 定义分隔符
$0   文本当前行的全部内容
$1   文本的第1列
$2   文件的第2列
$3   文件的第3列，依此类推
NR   文件当前行的行号
NF   文件当前行的列数（有几列）
awk 'ip[$1]++END{for (i in ip ){print i,ip[i]}}' /var/log/httpd/access_log
```

11.什么是灰度发布

```
比较平稳的过度方式升级或替换产品项目的方式
```

12.nginx如何实现调度器的功能

```
反向代理（7层应用层）httpd调度器 添加upstream集群
4层传输层TCP/UDP调度器 安装stream 模块 ，通过stream 配置upstream集群（在http 上方添加）
```

13.nginx有哪些优化

```bash
proxy主机修改Nginx配置文件，增加并发量（知晓即可）
[root@proxy nginx]# vim /usr/local/nginx/conf/nginx.conf
.. ..
   #user  nobody;
   worker_processes  2;     #与CPU核心数量一致
.. ..
   events {
       worker_connections  50000;
   }
.. ..
2）修改Nginx配置文件，增加数据包头部缓存大小
[root@proxy nginx]# vim conf/nginx.conf
.. ..
http {
    client_header_buffer_size    200k;    #添加，请求包头信息的缓存大小
    large_client_header_buffers  4 200k;  #添加，大请求包头部信息的缓存个数与容量
    include       mime.types;
    default_type  application/octet-stream;
.. ..
3）修改Nginx配置文件，定义对静态页面的缓存时间
[root@proxy nginx]# vim /usr/local/nginx/conf/nginx.conf
.. ..
    server {
        listen       80;
        server_name  localhost;
        #charset koi8-r;

        #access_log  logs/host.access.log  main;

        location / {
            root   html;
            index  index.html index.htm;
        }
        location ~* \.(jpg|txt|png|html)$ { #新添加 
            expires 30d;  #新添加，定义客户端缓存时间为30天
         }   #新添加
.. ..
```

14.ansible常见的模板有哪些，至少说出5个以上

```
shell
file
copy
yum
fetch
service

```

15.ansible如何定义变量

```bash
#主机清单变量 属于主机、组的格式[webservers:vars]下面进行变量定义

#剧本变量 变量矩阵和tasks同级别位置 变量文件：通过vars_files: file引用

#fact变量 
```

16.copy和template,fetch模块的区别

```bash
copy是将本地文件传输到被控节点，类似于上传操作
fetch是将被控节点的文件传输到本地，类似于下载
template上传具备特殊格式的文件（文件中包含变量），文件语法叫jinja2

```

17.handler的使用场景,如何实现循环

```bash
通过handlers定义一组任务
仅当某个任务触发（notify）handlers时才会执行相应任务
如果有多个notify触发执行handlers任务，也仅执行一次
仅当任务的执行状态为changed是handlers任务才执行
handlers任务在所有其他任务都执行后才执行

loop  	变量item 
单个元素 loop: [a,b,c,d]
		loop:
		  - a
		  - b
		  - c
		  - d
复杂变量 loop:
		  - {"key1":"value1","key2":"value2"} #键值对形式，引用item.key1 ,item.kye2
```

18.role角色创建后会出现哪些目录结构

```bash
roles:                  #角色必须放在roles目录下，可以自定义位置，默认/etc/ansible/roles/
    project:            #角色项目名称
        files:          #用于存放静态文件，如copy或script模块需要调用的文件
        templates:      #用于存放动态文件，即jinja2模板，template模块会自动到此目录下寻找模板文件
        tasks:          #定义任务列表的地方
            main.yml        #任务列表内容编写在此文件中
        handlers:       #定义触发器的地方
            main.yml        #触发器内容编写在此文件中
        vars:           #定义变量的地方（优先级高）
            main.yml        #变量定义在此文件中
        defaults:       #定义变量缺省值的地方（优先级低）
            main.yml
        meta:           #定义作者、版本等描述信息、依赖关系等
            main.yml
        README.md       #整个角色的描述信息
```

19.ansible调用配置文件的优先级

```bash
首先检测ANSIBLE_CONFIG变量定义的配置文件
其次检查当前目录下的./ansible.cfg文件
再次检查当前用户家目录下的~/ansible.cfg文件
最后检查/etc/ansible/ansible.cfg文件
```

20.Ivs和nginx与haproxy调度器之间的区别

```bash
LVS适用于需要高并发性和稳定性的场景
Nginx适用于静态文件服务和反向代理等应用层负载均衡场景
HAProxy则具备较为丰富的功能和灵活性，适用于多种负载均衡场景

LVS：Linux Virtual Server

优点：

高性能：LVS使用Linux内核中的IP负载均衡技术，能够实现非常高的并发处理能力
稳定性：LVS经过长时间的实践应用，成熟稳定，被广泛使用
可用性：支持高可用性的配置，可以实现故障自动切换，提供无中断的服务
灵活性：可根据需要采用多种负载均衡算法，如轮询、加权轮询、哈希等
缺点：

配置复杂：相对于其他两个技术，LVS的配置相对较为复杂，需要更深入的了解和配置
功能相对局限：LVS主要是一种传输层负载均衡技术，无法像Nginx和HAProxy那样对应用层协议进行处理
Nginx

优点

高性能：Nginx采用了基于事件驱动的异步非阻塞架构，能够处理大量并发连接
负载均衡：Nginx具备内置的负载均衡功能，可以根据配置进行请求的转发
丰富的功能：Nginx支持反向代理、静态文件服务、缓存、SSL等，在Web服务器领域有很广泛的应用
缺点

功能相对较少：相对于LVS和HAProxy，Nginx在负载均衡算法和健康检查等方面的功能相对较少
限制于应用层协议：Nginx只能对HTTP和HTTPS等应用层协议进行处理，无法处理其他协议
Haproxy

优点

灵活性：HAProxy支持丰富的负载均衡算法和会话保持方式，可以根据需求进行灵活配置
完整的功能：HAProxy支持高可用性配置、健康检查、故障恢复、SSL等功能，在负载均衡领域应用广泛
高性能：HAProxy性能优良，能够处理大量并发连接，并且支持异步IO模型
缺点

内存占用：相对于Nginx和LVS，HAProxy在处理大量连接时消耗的内存稍高一些
高可用性：HAProxy需要借助额外的工具来实现高可用性，例如Keepalived
```



21.ceph常见的组件有哪些

```bash
监视器 MON(Monitor)
管理器 MGR(Manager)
OSD (Object Storage Daemon)
MDS (Metadata Server)
RGW (Rados Gateway)

```

22.zabbix监控模板的创建流程，做过哪些自定义监控的key值



23.zabbix主动监控和被动监控的区别



24.protheus监控的流程



25.keepalive的工作原理

```bash
Keepalived检测每个服务器节点状态
服务器节点异常或者工作出现故障，keepalived将故障节点从集群系统中剔除
节点恢复后，再将其加入到集群系统中
```

26.iptables如何防止别人访问我的80端口服务，写成语句

```bash
iptables -A INPUT --dport 80 -j DROP/REJECT
```

27.如何抓取本机的eth0网卡的访问web服务的情况

```bash
sudo tcpdump -i eth0 -n port 80  -w web_traffic.pcap
```